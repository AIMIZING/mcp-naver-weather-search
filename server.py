# server.py
import sys
import time
import json
import logging
import threading
from typing import Dict, Any, Optional

import requests
from bs4 import BeautifulSoup
from cachetools import TTLCache

from mcp.server.fastmcp import FastMCP
import os

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ê¸°ë³¸ ì„¤ì •
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

CACHE_TTL_SECONDS = int(os.getenv("CACHE_TTL_SECONDS", "600"))
RATE_LIMIT_INTERVAL = float(os.getenv("RATE_LIMIT_INTERVAL", "1.0"))

mcp = FastMCP("Naver Weather MCP (Scraping)")

LOG_LEVEL = logging.INFO
logging.basicConfig(level=LOG_LEVEL, format="%(asctime)s - %(levelname)s - %(message)s")
log = logging.getLogger("naver-weather")

# ë„¤ì´ë²„ ê²€ìƒ‰ URL í…œí”Œë¦¿
SEARCH_URL = "https://search.naver.com/search.naver?query={query}"

# HTTP ì„¤ì •
DEFAULT_TIMEOUT = 6.0
USER_AGENT = (
    "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
    "AppleWebKit/537.36 (KHTML, like Gecko) "
    "Chrome/124.0.0.0 Safari/537.36"
)

# ìºì‹œ/ë ˆì´íŠ¸ë¦¬ë°‹
CACHE_TTL_SECONDS = 600  # 10ë¶„
cache: TTLCache[str, Dict[str, Any]] = TTLCache(maxsize=256, ttl=CACHE_TTL_SECONDS)

RATE_LIMIT_INTERVAL = 1.0  # ì´ˆë‹¹ 1íšŒ
_last_request_ts = 0.0
_rl_lock = threading.Lock()

# ì¬ì‹œë„
MAX_RETRIES = 3
BACKOFF_BASE = 0.8  # ì§€ìˆ˜ ë°±ì˜¤í”„ ì‹œì‘(ì´ˆ)

# ì„ íƒì(ë²„ì „ ê´€ë¦¬ ê°€ëŠ¥)
SELECTORS = {
    "temp_primary": [".temperature_text > strong"],  # ì˜ˆ: '23Â°'
    "status_primary": [".weather_main"],            # ì˜ˆ: 'ë§‘ìŒ'
    "sensible_temp": [".temperature_info .sensible em"],  # 'ì²´ê°ì˜¨ë„ 20Â°'
    # ë³´ì¡° ì„ íƒì (DOM ë³€ê²½ ì‹œ ì¶”ê°€)
    "temp_fallback": ["span.temperature_text strong", ".temperature_text"],
    "status_fallback": [".status .weather", ".status", ".weather"],
    "humidity_guess_blocks": [
        ".summary_list", ".weather_info", ".temperature_info"
    ],
}

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ìœ í‹¸: ë ˆì´íŠ¸ë¦¬ë°‹ / ìš”ì²­ / íŒŒì‹±
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _rate_limit():
    global _last_request_ts
    with _rl_lock:
        now = time.monotonic()
        wait = (_last_request_ts + RATE_LIMIT_INTERVAL) - now
        if wait > 0:
            time.sleep(wait)
        _last_request_ts = time.monotonic()

def _fetch_html(url: str) -> str:
    """ìš”ì²­ ì¬ì‹œë„ + ì§€ìˆ˜ ë°±ì˜¤í”„ë¡œ HTML ê°€ì ¸ì˜¤ê¸°"""
    headers = {"User-Agent": USER_AGENT, "Accept-Language": "ko-KR,ko;q=0.9"}
    err: Optional[Exception] = None
    for attempt in range(1, MAX_RETRIES + 1):
        try:
            _rate_limit()
            resp = requests.get(url, headers=headers, timeout=DEFAULT_TIMEOUT)
            # 429/5xxëŠ” ì¬ì‹œë„
            if resp.status_code >= 500 or resp.status_code == 429:
                raise requests.HTTPError(f"HTTP {resp.status_code}: {resp.text[:200]}")
            resp.raise_for_status()
            return resp.text
        except Exception as e:
            err = e
            sleep_for = BACKOFF_BASE * (2 ** (attempt - 1))
            log.warning(f"[fetch] attempt {attempt}/{MAX_RETRIES} failed: {e}. backoff {sleep_for:.1f}s")
            time.sleep(sleep_for)
    raise RuntimeError(f"Failed to fetch after retries: {err}")

def _first_text(soup: BeautifulSoup, selectors: list[str]) -> Optional[str]:
    for sel in selectors:
        el = soup.select_one(sel)
        if el:
            txt = el.get_text(strip=True)
            if txt:
                return txt
    return None

def _guess_humidity(soup: BeautifulSoup) -> Optional[str]:
    """'ìŠµë„' í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ìˆ«ì ì¶”ì •(ë ˆì´ì•„ì›ƒ ë³€í™” ëŒ€ë¹„ ì™„í™”)"""
    import re
    for block_sel in SELECTORS["humidity_guess_blocks"]:
        block = soup.select_one(block_sel)
        if not block:
            continue
        text = block.get_text(" ", strip=True)
        m = re.search(r"ìŠµë„\s*([0-9]{1,3})\s*%?", text)
        if m:
            return m.group(1) + "%"
    return None

def _normalize_temp(txt: str) -> str:
    # ì˜ˆ: "23Â°" or "23ë„" â†’ "23Â°C" í˜•íƒœë¡œ
    t = txt.replace("ë„", "").replace(" ", "").replace("Â°", "")
    if t.startswith("+"): t = t[1:]
    return f"{t}Â°C" if t else txt

def _parse_weather(html: str, region: str) -> Dict[str, Any]:
    soup = BeautifulSoup(html, "html.parser")

    temp = _first_text(soup, SELECTORS["temp_primary"]) or _first_text(soup, SELECTORS["temp_fallback"])
    status = _first_text(soup, SELECTORS["status_primary"]) or _first_text(soup, SELECTORS["status_fallback"])
    sensible = _first_text(soup, SELECTORS["sensible_temp"])
    humidity = _guess_humidity(soup)

    if temp:
        temp = _normalize_temp(temp)

    parsed = {
        "region": region,
        "status": status,
        "temperature": temp,
        "sensible_temperature": sensible,
        "humidity": humidity,
        "source": SEARCH_URL.format(query=f"{region}+ë‚ ì”¨"),
        "timestamp": int(time.time()),
    }
    return parsed

def _format_text(data: Dict[str, Any]) -> str:
    lines = [f"[ë„¤ì´ë²„ ë‚ ì”¨] {data.get('region','-')}"]
    if data.get("status"): lines.append(f"- ìƒíƒœ: {data['status']}")
    if data.get("temperature"): lines.append(f"- ê¸°ì˜¨: {data['temperature']}")
    if data.get("sensible_temperature"): lines.append(f"- ì²´ê°ì˜¨ë„: {data['sensible_temperature']}")
    if data.get("humidity"): lines.append(f"- ìŠµë„: {data['humidity']}")
    if data.get("source"): lines.append(f"- ì°¸ê³ : {data['source']}")
    # ì„ íƒì ì‹¤íŒ¨ ëŒ€ë¹„
    if len(lines) <= 2:
        lines.append("- ì•ˆë‚´: ì¼ë¶€ ì •ë³´ ìˆ˜ì§‘ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.")
        if data.get("source"): lines.append(f"- ì°¸ê³ : {data['source']}")
    return "\n".join(lines)

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# MCP Tool
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
@mcp.tool(
    name="get_weather_by_region",
    description="ì§€ì—­ëª…ì„ ë°›ì•„ ë„¤ì´ë²„ ê²€ìƒ‰ ê²°ê³¼(ë‚ ì”¨ ëª¨ë“ˆ)ì—ì„œ í˜„ì¬ ìƒíƒœ/ê¸°ì˜¨ ë“±ì„ ì¡°íšŒí•©ë‹ˆë‹¤. format='text'|'json'"
)
def get_weather_by_region(region: str, format: str = "text") -> str:
    """
    Args:
        region: ì¡°íšŒí•  ì§€ì—­ëª… (ì˜ˆ: 'ì„œìš¸', 'ë¶€ì‚° í•´ìš´ëŒ€', 'Jeju')
        format: 'text' ë˜ëŠ” 'json' (ê¸°ë³¸: text)
    """
    region_key = region.strip()
    if not region_key:
        return "ì§€ì—­ëª…ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤. ì˜ˆ: region='ì„œìš¸'"

    # ìºì‹œ
    if region_key in cache:
        data = cache[region_key]
        log.info(f"[cache] hit for region='{region_key}'")
    else:
        try:
            url = SEARCH_URL.format(query=f"{region_key}+ë‚ ì”¨")
            html = _fetch_html(url)
            data = _parse_weather(html, region_key)
            cache[region_key] = data
        except Exception as e:
            log.exception("weather fetch/parse failed")
            # ì¶•ì•½ ì˜¤ë¥˜ ë©”ì‹œì§€(ë‚´ë¶€ ì •ë³´ ë…¸ì¶œ ë°©ì§€)
            return f"[ì˜¤ë¥˜] ë‚ ì”¨ ì •ë³´ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘ ë¬¸ì œê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”. (reason: {str(e)[:120]})"

    if format.lower() == "json":
        return json.dumps(data, ensure_ascii=False, indent=2)
    return _format_text(data)

# (ì„ íƒ) ë¦¬ì†ŒìŠ¤: ì œê³µ í•„ë“œ ì•ˆë‚´
@mcp.resource(
    uri="naver://weather/fields",
    name="supported_fields",
    description="ì´ MCPê°€ ë°˜í™˜ ê°€ëŠ¥í•œ í•„ë“œ ëª©ë¡ì„ ì œê³µí•©ë‹ˆë‹¤."
)
def supported_fields() -> Dict[str, Any]:
    return {
        "fields": ["region", "status", "temperature", "sensible_temperature", "humidity", "source", "timestamp"],
        "cache_ttl_seconds": CACHE_TTL_SECONDS,
        "rate_limit_seconds": RATE_LIMIT_INTERVAL,
    }

# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
# ì‹¤í–‰
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
if __name__ == "__main__":
    print("ğŸ”§ Naver Weather MCP (scraping) startingâ€¦", file=sys.stderr)
    mcp.run(transport="stdio")
